# task4 实验报告

## 什么是GAN

> 来自维基的内容
> Generative Adversarial Networks  (生成对抗网络简称（GAN）是一类用于无监督机器学习的人工智能算法，由在零和游戏框架中相互竞争的两个神经网络系统实现。他们是由Ian Goodfellow 等人介绍的。在2014年这种技术可以生成照片看起来至少在表面上真实的人的观察员，有很多的现实特征（虽然在测试中的人可以真正告诉在许多情况下产生）

生成对抗网络（GAN）由2个重要的部分构成：

1. **生成器(Generator**)：通过机器生成数据（大部分情况下是图像），目的是“骗过”判别器
2. **判别器(Discriminator**)：判断这张图像是真实的还是机器生成的，目的是找出生成器做的“假数据”

**第一阶段：固定「判别器D」，训练「生成器G」**

我们使用一个还 OK的 判别器，让一个「生成器G」不断生成“假数据”，然后给这个「判别器D」去判断。

一开始，「生成器G」还很弱，所以很容易被揪出来。

但是随着不断的训练，「生成器G」技能不断提升，最终骗过了「判别器D」。

到了这个时候，「判别器D」基本属于瞎猜的状态，判断是否为假数据的概率为50%。

**第二阶段：固定「生成器G」，训练「判别器D」**

当通过了第一阶段，继续训练「生成器G」就没有意义了。这个时候我们固定「生成器G」，然后开始训练「判别器D」。

「判别器D」通过不断训练，提高了自己的鉴别能力，最终他可以准确的判断出所有的假图片。

到了这个时候，「生成器G」已经无法骗过「判别器D」。

**然后：循环阶段一和阶段二**

<img src="https://www.hualigs.cn/image/6059b7283bbb9.jpg" style="zoom:67%;" />

> (a) StackedGAN  and (b) Progressive GAN

## GAN的实际应用：
- 生成图像数据集
  
  > 人工智能的训练是需要大量的数据集的，如果全部靠人工收集和标注，成本是很高的。GAN 可以自动的生成一些数据集，提供低成本的训练数据。
- 生成人脸照片
  > 生成人脸照片是大家很熟悉的应用，但是生成出来的照片用来做什么是需要思考的问题。因为这种人脸照片还处于法律的边缘。
  > GAN 不但能生成人脸，还能生成其他类型的照片，甚至是漫画人物。
  > 在2017年标题为“ [姿势引导人形象生成](https://arxiv.org/abs/1705.09368) ”的论文中，可以自动生成人体模特，并且使用新的姿势
- 图像到图像的转换
  >简单说就是把一种形式的图像转换成另外一种形式的图像，就好像加滤镜一样神奇。例如：
  - 把草稿转换成照片
  - 把卫星照片转换为Google地图的图片
  - 把照片转换成油画
  - 把白天转换成黑夜
- 图像编辑
  > 使用GAN可以生成特定的照片，例如更换头发颜色、更改面部表情、甚至是改变性别——啊螺丝扣搭街、、比如最近的那个faceapp
  > 
  > 给GAN一张照片，他就能生成一张分辨率更高的照片，使得这个照片更加清晰
  > 假如照片中有一个区域出现了问题（例如被涂上颜色或者被抹去），GAN可以修复这个区域，还原成原始的状态。

## GAN的优缺点：

优点：

1. 能更好建模数据分布（图像更锐利、清晰）
2. 理论上，GANs 能训练任何一种生成器网络。其他的框架需要生成器网络有一些特定的函数形式，比如输出层是高斯的。
3. 无需利用马尔科夫链反复采样，无需在学习过程中进行推断，没有复杂的变分下界，避开近似计算棘手的概率的难题。

缺点：

1. 难训练，不稳定。生成器和判别器之间需要很好的同步，但是在实际训练中很容易D收敛，G发散。D/G 的训练需要精心的设计。
2. 模式缺失（Mode Collapse）问题。GANs的学习过程可能出现模式缺失，生成器开始退化，总是生成同样的样本点，无法继续学习。

## 实验报告

生成部分：
我们一开始尝试使用MINST手写数字集，作为训练的数据

一开始，我们先学习使用了最传统的GAN，
即使用全连接层搭建生成器和判别器。

全连接层在表达上更丰富更具有潜力，大量的参数让它能够拟合更多的概率分布，
但随之而来的代价，确实参数过多，对存储和训练带来了巨大的负担
在28x28像素的MNIST上的良好表现难以复制到256x256的照片与画作上

我们随后学习了DCGAN——作为GAN系列中跨时代的网络模型，DCGAN向
GAN中引入了卷积层。这大大降低了GAN所需的算力，减少了参数，并且卷积层
与图片属性较为契合，能够增大图片相邻区块的联系性，和他们的整体表达性。

我们搭建的DCGAN在MNIST一样十分成功，但是移植到印象派图片的生成后，
生成的图片却充满噪点，在大量阅读DCGAN的文献，和成功的案例之后。
我们发现DCGAN主要应用在大量构图相似，风格统一的图片集上，例如人脸或头像的生成。
我们认为DCGAN在特征较为一致明显的数据集上才能较好的perform。
因此，我们使用DCGAN凭空生成画作的构想遭到了挫折。

因此我们转而尝试通过风格转换(Style Tansform)的方式，基于真实的图片生成印象派画作。
我们选用了有名的CycleGAN作为风格转换的模型。

GAN一直以难以训练著称，GAN强调生成器和判别器的交错对抗，因此超参的选择十分重要，
有些参数能训练出良好的网络，而另一些生成的网络充满噪点。而CycleGAN则尤其难以训练，
由于CycleGAN的loss分为三部分：身份损失(identity loss), 风格损失，和循环损失(Cycle loss)
这三者之间的比例关系对于一个CycleGAN的表达至关重要。而确定这些参数，正需要nni这样的超参调优工具的帮助

nni在GAN的训练中便能扮演良好的自动调参的角色。但是在使用nni对CycleGan的训练进行超参调优之前
我们还有一个障碍，那就是如何评价在前几个epoch的训练后评价CycleGan表现的好坏，

在理论的研究和实践尝试之后我们了解了，GAN本质上是从一个空间中的概率分布拟合另一个概率分布，
而前几个epoch中一旦GAN拟合的方向尝试错误，那么最终便难以达到好的结果，
于是我们预先训练了一个Resnet用于分类图片和印象派画作。我们将CycleGan中途输出的由图片转换的
画作扔进Resnet，将他们的概率之和作为评估CycleGAN的重要参数。

在漫长的训练之后，我们得到了一组较好的参数，并继续训练，获得了较为理想的网络，达到了照片转为印象派画作的效果。
这个项目让我们感受到了nni的强大，他帮助我们快速找到了合理的超参，节省了我们大量调参的时间精力，
帮助我们获得了较好的结果。

受限于经验和硬件，我们只训练了图片和印象派画作的转换，立项的目标有几个没能完成。但在项目中我们学习掌握并实践了几个经典的GAN模型，
同时将他们的训练与nni结合起来，体会到了nni超参调优工具的强大性能。作为大一新生的我们，有幸参与到这个项目中，
在实践中学习人工智能的知识，和学长姐一起参加项目，交流经验，收益颇丰。

## 资料引用

论文：

- https://arxiv.org/abs/1406.2661

文章：

- https://easyai.tech/ai-definition/gan/ 